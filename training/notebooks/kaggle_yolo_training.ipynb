{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnam Traffic Detection - YOLOv8 Training on Kaggle\n",
    "\n",
    "This notebook trains a custom YOLOv8 model for Vietnam traffic detection.\n",
    "\n",
    "**Classes:** car, truck, motorcycle, bus, ambulance (5 classes)\n",
    "\n",
    "**Requirements:**\n",
    "- Kaggle GPU runtime (P100 or T4)\n",
    "- Dataset uploaded to Kaggle Datasets\n",
    "\n",
    "**Estimated Training Time:** 2-4 hours for 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics>=8.0.0 -q\n",
    "!pip install albumentations>=1.3.0 -q\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "# Set working directory\n",
    "WORK_DIR = Path('/kaggle/working')\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"Working directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration\n",
    "\n",
    "**IMPORTANT:** Before running this cell, upload your dataset to Kaggle:\n",
    "1. Go to kaggle.com/datasets/new\n",
    "2. Upload your labeled dataset (in YOLO format)\n",
    "3. Note the dataset path (e.g., `/kaggle/input/vietnam-traffic-dataset`)\n",
    "4. Update `DATASET_PATH` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURE YOUR DATASET PATH HERE\n",
    "# ============================================================\n",
    "DATASET_PATH = '/kaggle/input/vietnam-traffic-dataset'  # <-- UPDATE THIS!\n",
    "# ============================================================\n",
    "\n",
    "# Verify dataset exists\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"ERROR: Dataset not found at {DATASET_PATH}\")\n",
    "    print(\"Please upload your dataset to Kaggle and update DATASET_PATH\")\n",
    "else:\n",
    "    print(f\"Dataset found at: {DATASET_PATH}\")\n",
    "    print(\"Contents:\")\n",
    "    for item in os.listdir(DATASET_PATH):\n",
    "        item_path = os.path.join(DATASET_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            count = len(os.listdir(item_path))\n",
    "            print(f\"  {item}/ ({count} items)\")\n",
    "        else:\n",
    "            print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset.yaml for training\n",
    "# This maps to your uploaded dataset structure\n",
    "\n",
    "dataset_config = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': 5,\n",
    "    'names': {\n",
    "        0: 'car',\n",
    "        1: 'truck',\n",
    "        2: 'motorcycle',\n",
    "        3: 'bus',\n",
    "        4: 'ambulance'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save dataset.yaml\n",
    "dataset_yaml_path = WORK_DIR / 'dataset.yaml'\n",
    "with open(dataset_yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Dataset config saved to: {dataset_yaml_path}\")\n",
    "print(\"\\nConfig contents:\")\n",
    "with open(dataset_yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "def count_files(directory, extension='*'):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    if extension == '*':\n",
    "        return len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
    "    return len([f for f in os.listdir(directory) if f.endswith(extension)])\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_dir = os.path.join(DATASET_PATH, 'images', split)\n",
    "    lbl_dir = os.path.join(DATASET_PATH, 'labels', split)\n",
    "    \n",
    "    n_images = count_files(img_dir)\n",
    "    n_labels = count_files(lbl_dir, '.txt')\n",
    "    \n",
    "    print(f\"{split.capitalize():8s}: {n_images:4d} images, {n_labels:4d} labels\")\n",
    "    \n",
    "    if n_images != n_labels:\n",
    "        print(f\"  WARNING: Image/label count mismatch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Configuration\n",
    "\n",
    "Optimized settings for Vietnam traffic detection:\n",
    "- YOLOv8l (large) for best accuracy\n",
    "- Transfer learning from COCO pretrained weights\n",
    "- Augmentation tuned for traffic camera footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING HYPERPARAMETERS - Adjust as needed\n",
    "# ============================================================\n",
    "\n",
    "TRAINING_CONFIG = {\n",
    "    # Model selection\n",
    "    'model': 'yolov8l.pt',       # Options: yolov8n, yolov8s, yolov8m, yolov8l, yolov8x\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 100,               # Number of training epochs\n",
    "    'batch': 16,                 # Batch size (reduce if OOM)\n",
    "    'imgsz': 640,                # Image size (640 is standard)\n",
    "    'patience': 20,              # Early stopping patience\n",
    "    \n",
    "    # Learning rate\n",
    "    'lr0': 0.01,                 # Initial learning rate\n",
    "    'lrf': 0.01,                 # Final learning rate (lr0 * lrf)\n",
    "    'warmup_epochs': 3,          # Warmup epochs\n",
    "    \n",
    "    # Optimizer\n",
    "    'optimizer': 'SGD',          # Optimizer (SGD, Adam, AdamW)\n",
    "    'momentum': 0.937,           # SGD momentum\n",
    "    'weight_decay': 0.0005,      # Weight decay\n",
    "    \n",
    "    # Augmentation (tuned for traffic cameras)\n",
    "    'hsv_h': 0.015,              # HSV-Hue augmentation\n",
    "    'hsv_s': 0.7,                # HSV-Saturation\n",
    "    'hsv_v': 0.4,                # HSV-Value (brightness)\n",
    "    'degrees': 0.0,              # Rotation (disabled for traffic)\n",
    "    'translate': 0.1,            # Translation\n",
    "    'scale': 0.5,                # Scale\n",
    "    'shear': 0.0,                # Shear (disabled)\n",
    "    'perspective': 0.0,          # Perspective (disabled)\n",
    "    'flipud': 0.0,               # Vertical flip (disabled)\n",
    "    'fliplr': 0.5,               # Horizontal flip\n",
    "    'mosaic': 1.0,               # Mosaic augmentation\n",
    "    'mixup': 0.0,                # MixUp (disabled)\n",
    "    \n",
    "    # Other settings\n",
    "    'workers': 4,                # DataLoader workers\n",
    "    'device': 0,                 # GPU device (0 for single GPU)\n",
    "    'project': 'vietnam_traffic',\n",
    "    'name': 'yolov8l_custom',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'verbose': True,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for k, v in TRAINING_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained YOLOv8 model\n",
    "model = YOLO(TRAINING_CONFIG['model'])\n",
    "\n",
    "print(f\"Model loaded: {TRAINING_CONFIG['model']}\")\n",
    "print(f\"Model type: {type(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "# This cell will take 2-4 hours depending on your dataset size and GPU\n",
    "\n",
    "results = model.train(\n",
    "    data=str(dataset_yaml_path),\n",
    "    epochs=TRAINING_CONFIG['epochs'],\n",
    "    batch=TRAINING_CONFIG['batch'],\n",
    "    imgsz=TRAINING_CONFIG['imgsz'],\n",
    "    patience=TRAINING_CONFIG['patience'],\n",
    "    \n",
    "    # Learning rate\n",
    "    lr0=TRAINING_CONFIG['lr0'],\n",
    "    lrf=TRAINING_CONFIG['lrf'],\n",
    "    warmup_epochs=TRAINING_CONFIG['warmup_epochs'],\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer=TRAINING_CONFIG['optimizer'],\n",
    "    momentum=TRAINING_CONFIG['momentum'],\n",
    "    weight_decay=TRAINING_CONFIG['weight_decay'],\n",
    "    \n",
    "    # Augmentation\n",
    "    hsv_h=TRAINING_CONFIG['hsv_h'],\n",
    "    hsv_s=TRAINING_CONFIG['hsv_s'],\n",
    "    hsv_v=TRAINING_CONFIG['hsv_v'],\n",
    "    degrees=TRAINING_CONFIG['degrees'],\n",
    "    translate=TRAINING_CONFIG['translate'],\n",
    "    scale=TRAINING_CONFIG['scale'],\n",
    "    shear=TRAINING_CONFIG['shear'],\n",
    "    perspective=TRAINING_CONFIG['perspective'],\n",
    "    flipud=TRAINING_CONFIG['flipud'],\n",
    "    fliplr=TRAINING_CONFIG['fliplr'],\n",
    "    mosaic=TRAINING_CONFIG['mosaic'],\n",
    "    mixup=TRAINING_CONFIG['mixup'],\n",
    "    \n",
    "    # Other\n",
    "    workers=TRAINING_CONFIG['workers'],\n",
    "    device=TRAINING_CONFIG['device'],\n",
    "    project=TRAINING_CONFIG['project'],\n",
    "    name=TRAINING_CONFIG['name'],\n",
    "    exist_ok=TRAINING_CONFIG['exist_ok'],\n",
    "    pretrained=TRAINING_CONFIG['pretrained'],\n",
    "    verbose=TRAINING_CONFIG['verbose'],\n",
    "    seed=TRAINING_CONFIG['seed'],\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model weights\n",
    "best_model_path = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name'] / 'weights' / 'best.pt'\n",
    "last_model_path = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name'] / 'weights' / 'last.pt'\n",
    "\n",
    "print(f\"Best model: {best_model_path}\")\n",
    "print(f\"Last model: {last_model_path}\")\n",
    "print(f\"\\nBest model exists: {best_model_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and run validation\n",
    "best_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Validate on validation set\n",
    "val_results = best_model.val(\n",
    "    data=str(dataset_yaml_path),\n",
    "    split='val',\n",
    "    batch=TRAINING_CONFIG['batch'],\n",
    "    imgsz=TRAINING_CONFIG['imgsz'],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print validation metrics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nmAP50:     {val_results.box.map50:.4f}\")\n",
    "print(f\"mAP50-95:  {val_results.box.map:.4f}\")\n",
    "\n",
    "print(\"\\nPer-class AP50:\")\n",
    "class_names = ['car', 'truck', 'motorcycle', 'bus', 'ambulance']\n",
    "for i, name in enumerate(class_names):\n",
    "    if i < len(val_results.box.ap50):\n",
    "        print(f\"  {name:12s}: {val_results.box.ap50[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on test set (if available)\n",
    "test_dir = os.path.join(DATASET_PATH, 'images', 'test')\n",
    "if os.path.exists(test_dir) and len(os.listdir(test_dir)) > 0:\n",
    "    print(\"Running evaluation on test set...\")\n",
    "    test_results = best_model.val(\n",
    "        data=str(dataset_yaml_path),\n",
    "        split='test',\n",
    "        batch=TRAINING_CONFIG['batch'],\n",
    "        imgsz=TRAINING_CONFIG['imgsz'],\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(f\"\\nTest mAP50:    {test_results.box.map50:.4f}\")\n",
    "    print(f\"Test mAP50-95: {test_results.box.map:.4f}\")\n",
    "else:\n",
    "    print(\"No test set found, skipping test evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves and confusion matrix\n",
    "from IPython.display import Image, display\n",
    "\n",
    "results_dir = Path(TRAINING_CONFIG['project']) / TRAINING_CONFIG['name']\n",
    "\n",
    "# Training curves\n",
    "results_png = results_dir / 'results.png'\n",
    "if results_png.exists():\n",
    "    print(\"Training Curves:\")\n",
    "    display(Image(filename=str(results_png), width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix_png = results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_png.exists():\n",
    "    print(\"Confusion Matrix:\")\n",
    "    display(Image(filename=str(confusion_matrix_png), width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions on validation images\n",
    "val_batch_png = results_dir / 'val_batch0_pred.jpg'\n",
    "if val_batch_png.exists():\n",
    "    print(\"Sample Predictions:\")\n",
    "    display(Image(filename=str(val_batch_png), width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Model\n",
    "\n",
    "Export the trained model in various formats for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX for cross-platform deployment\n",
    "onnx_path = best_model.export(format='onnx', imgsz=640, simplify=True)\n",
    "print(f\"ONNX model exported to: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TorchScript for PyTorch deployment\n",
    "torchscript_path = best_model.export(format='torchscript', imgsz=640)\n",
    "print(f\"TorchScript model exported to: {torchscript_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Trained Model\n",
    "\n",
    "Copy the trained model to the output directory for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for download\n",
    "output_dir = WORK_DIR / 'trained_model'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy best model\n",
    "shutil.copy(best_model_path, output_dir / 'vietnam_traffic_yolov8l_best.pt')\n",
    "shutil.copy(last_model_path, output_dir / 'vietnam_traffic_yolov8l_last.pt')\n",
    "\n",
    "# Copy ONNX if exists\n",
    "onnx_file = best_model_path.with_suffix('.onnx')\n",
    "if onnx_file.exists():\n",
    "    shutil.copy(onnx_file, output_dir / 'vietnam_traffic_yolov8l.onnx')\n",
    "\n",
    "# Copy results\n",
    "if results_png.exists():\n",
    "    shutil.copy(results_png, output_dir / 'training_results.png')\n",
    "if confusion_matrix_png.exists():\n",
    "    shutil.copy(confusion_matrix_png, output_dir / 'confusion_matrix.png')\n",
    "\n",
    "print(f\"\\nTrained model files copied to: {output_dir}\")\n",
    "print(\"\\nFiles available for download:\")\n",
    "for f in output_dir.iterdir():\n",
    "    size_mb = f.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {f.name}: {size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file for easy download\n",
    "import zipfile\n",
    "\n",
    "zip_path = WORK_DIR / 'vietnam_traffic_model.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file in output_dir.iterdir():\n",
    "        zipf.write(file, file.name)\n",
    "\n",
    "zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"\\nZip file created: {zip_path}\")\n",
    "print(f\"Size: {zip_size_mb:.1f} MB\")\n",
    "print(\"\\nDownload this file from the Output tab in Kaggle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Test Inference\n",
    "\n",
    "Test the trained model on a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find a sample image from validation set\n",
    "val_images_dir = Path(DATASET_PATH) / 'images' / 'val'\n",
    "if val_images_dir.exists():\n",
    "    sample_images = list(val_images_dir.glob('*.jpg'))[:3]\n",
    "    \n",
    "    if sample_images:\n",
    "        fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "        if len(sample_images) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, img_path in zip(axes, sample_images):\n",
    "            # Run inference\n",
    "            results = best_model(str(img_path), verbose=False)\n",
    "            \n",
    "            # Plot result\n",
    "            result_img = results[0].plot()\n",
    "            result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            ax.imshow(result_img)\n",
    "            ax.set_title(img_path.name)\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'sample_predictions.png', dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nSample predictions saved to: {output_dir / 'sample_predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Integration Instructions\n",
    "\n",
    "After training, follow these steps to integrate the model:\n",
    "\n",
    "1. **Download** `vietnam_traffic_model.zip` from Kaggle Output\n",
    "\n",
    "2. **Extract** and copy `vietnam_traffic_yolov8l_best.pt` to your project's `video_detection/` folder\n",
    "\n",
    "3. **Update** `video_detection/config/config.yaml`:\n",
    "```yaml\n",
    "model:\n",
    "  path: \"vietnam_traffic_yolov8l_best.pt\"  # Changed from yolov8l.pt\n",
    "```\n",
    "\n",
    "4. **Update** `video_detection/detector/yolo_detector.py` class mapping (if needed):\n",
    "```python\n",
    "# The trained model uses these class indices:\n",
    "# 0: car, 1: truck, 2: motorcycle, 3: bus, 4: ambulance\n",
    "```\n",
    "\n",
    "5. **Test** the model:\n",
    "```bash\n",
    "cd video_detection\n",
    "python main.py --video ../dataset/01.mp4 --model vietnam_traffic_yolov8l_best.pt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: {TRAINING_CONFIG['model']}\")\n",
    "print(f\"Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"Image size: {TRAINING_CONFIG['imgsz']}\")\n",
    "print(f\"\\nValidation mAP50: {val_results.box.map50:.4f}\")\n",
    "print(f\"Validation mAP50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  - vietnam_traffic_yolov8l_best.pt (main model)\")\n",
    "print(f\"  - vietnam_traffic_yolov8l.onnx (ONNX export)\")\n",
    "print(f\"  - vietnam_traffic_model.zip (all files)\")\n",
    "print(f\"\\nDownload from Kaggle Output tab!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
