"""
Topic Validator - Validates if user message is related to Vietnamese traffic law.
Filters out off-topic questions BEFORE sending to LLM to save costs and maintain focus.
"""

import re
from dataclasses import dataclass
from typing import Optional, List, Tuple
from enum import Enum


class TopicCategory(Enum):
    """Categories of valid traffic-related topics."""

    TRAFFIC_VIOLATION = "traffic_violation"
    DRIVER_LICENSE = "driver_license"
    SPEED_LIMIT = "speed_limit"
    ALCOHOL_REGULATION = "alcohol_regulation"
    TRAFFIC_RULES = "traffic_rules"
    TRAFFIC_SIGNS = "traffic_signs"
    VEHICLE_REGISTRATION = "vehicle_registration"
    INSURANCE = "insurance"
    ACCIDENT = "accident"
    TRAFFIC_STATUS = "traffic_status"
    GREETING = "greeting"
    OFF_TOPIC = "off_topic"


@dataclass
class ValidationResult:
    """Result of topic validation."""

    is_valid: bool
    confidence: float  # 0.0 to 1.0
    category: TopicCategory
    reason: str
    suggested_response: Optional[str] = None


class TopicValidator:
    """
    Multi-layer topic validator for Vietnamese traffic law chatbot.

    Validation Strategy:
    1. Check for greetings (always valid, but handled differently)
    2. Check blacklist keywords (definitely off-topic)
    3. Check whitelist keywords (definitely on-topic)
    4. Calculate relevance score for edge cases
    """

    # Greeting patterns - always valid but handled separately
    GREETING_PATTERNS = [
        r"^(xin\s*)?chÃ o",
        r"^hello",
        r"^hi\b",
        r"^hey\b",
        r"^chÃ o\s*báº¡n",
        r"^chÃ o\s*bot",
        r"^báº¡n\s*(lÃ \s*)?ai",
        r"^giá»›i\s*thiá»‡u",
        r"^cáº£m\s*Æ¡n",
        r"^thank",
        r"^táº¡m\s*biá»‡t",
        r"^bye",
    ]

    # Whitelist: Traffic-related keywords (Vietnamese)
    TRAFFIC_KEYWORDS = [
        # Violations & Penalties
        "vi pháº¡m",
        "pháº¡t",
        "xá»­ pháº¡t",
        "má»©c pháº¡t",
        "tiá»n pháº¡t",
        "bá»‹ pháº¡t",
        "nghá»‹ Ä‘á»‹nh",
        "nÄ‘ 168",
        "nd 168",
        "168/2024",
        # Vehicles
        "xe mÃ¡y",
        "xe may",
        "Ã´ tÃ´",
        "oto",
        "xe hÆ¡i",
        "xe con",
        "mÃ´ tÃ´",
        "moto",
        "xe táº£i",
        "xe khÃ¡ch",
        "xe buÃ½t",
        "xe bus",
        "xe Ä‘áº¡p",
        "xe Ä‘iá»‡n",
        "phÆ°Æ¡ng tiá»‡n",
        "xe cÆ¡ giá»›i",
        # Driver's License
        "báº±ng lÃ¡i",
        "bang lai",
        "gplx",
        "giáº¥y phÃ©p lÃ¡i xe",
        "giay phep lai xe",
        "háº¡ng a1",
        "háº¡ng a2",
        "háº¡ng b1",
        "háº¡ng b2",
        "háº¡ng c",
        "háº¡ng d",
        "háº¡ng e",
        "thi báº±ng",
        "Ä‘á»•i báº±ng",
        "cáº¥p báº±ng",
        "gia háº¡n báº±ng",
        # Points System
        "Ä‘iá»ƒm",
        "trá»« Ä‘iá»ƒm",
        "há»‡ thá»‘ng Ä‘iá»ƒm",
        "12 Ä‘iá»ƒm",
        "tÆ°á»›c báº±ng",
        "tÆ°á»›c gplx",
        # Speed
        "tá»‘c Ä‘á»™",
        "giá»›i háº¡n tá»‘c Ä‘á»™",
        "km/h",
        "kmh",
        "cháº¡y nhanh",
        "quÃ¡ tá»‘c Ä‘á»™",
        "vÆ°á»£t tá»‘c Ä‘á»™",
        # Alcohol
        "ná»“ng Ä‘á»™ cá»“n",
        "nong do con",
        "cá»“n",
        "Ä‘á»™ cá»“n",
        "rÆ°á»£u bia",
        "uá»‘ng rÆ°á»£u",
        "say rÆ°á»£u",
        "Ä‘o ná»“ng Ä‘á»™",
        "thá»•i ná»“ng Ä‘á»™",
        "mg/l",
        "Ä‘Ã£ uá»‘ng",
        # Traffic Rules
        "giao thÃ´ng",
        "luáº­t giao thÃ´ng",
        "luáº­t gtÄ‘b",
        "an toÃ n giao thÃ´ng",
        "atgt",
        "quy táº¯c",
        "quy Ä‘á»‹nh",
        # Traffic Signs & Signals
        "Ä‘Ã¨n Ä‘á»",
        "Ä‘Ã¨n xanh",
        "Ä‘Ã¨n vÃ ng",
        "Ä‘Ã¨n giao thÃ´ng",
        "biá»ƒn bÃ¡o",
        "biá»ƒn cáº¥m",
        "biá»ƒn hiá»‡u",
        "váº¡ch káº» Ä‘Æ°á»ng",
        # Road Types
        "Ä‘Æ°á»ng cao tá»‘c",
        "cao tá»‘c",
        "Ä‘Æ°á»ng quá»‘c lá»™",
        "quá»‘c lá»™",
        "Ä‘Æ°á»ng tá»‰nh",
        "Ä‘Æ°á»ng ná»™i thÃ nh",
        "Ä‘Ã´ thá»‹",
        "ngoÃ i Ä‘Ã´ thá»‹",
        # Actions
        "vÆ°á»£t Ä‘Ã¨n Ä‘á»",
        "cháº¡y ngÆ°á»£c chiá»u",
        "láº¥n lÃ n",
        "khÃ´ng Ä‘á»™i mÅ©",
        "mÅ© báº£o hiá»ƒm",
        "khÃ´ng tháº¯t dÃ¢y",
        "dÃ¢y an toÃ n",
        "Ä‘i sai lÃ n",
        "chá»Ÿ quÃ¡ sá»‘ ngÆ°á»i",
        "quÃ¡ táº£i",
        "khÃ´ng cÃ³ báº±ng",
        "háº¿t háº¡n báº±ng",
        "Ä‘áº­u xe",
        "Ä‘á»— xe",
        "dá»«ng xe",
        "quay Ä‘áº§u",
        # Documents
        "giáº¥y tá» xe",
        "Ä‘Äƒng kÃ½ xe",
        "Ä‘Äƒng kiá»ƒm",
        "báº£o hiá»ƒm xe",
        "cavet",
        "cÃ  váº¹t",
        # Accident
        "tai náº¡n",
        "va cháº¡m",
        "Ä‘Ã¢m xe",
        "tÃ´ng xe",
        # Questions about traffic
        "lÃ¡i xe",
        "Ä‘iá»u khiá»ƒn xe",
        "chá»Ÿ ngÆ°á»i",
        "chá»Ÿ hÃ ng",
        # Traffic status / congestion queries
        "Ã¹n táº¯c",
        "táº¯c Ä‘Æ°á»ng",
        "káº¹t xe",
        "Ä‘Ã´ng xe",
        "tÃ¬nh hÃ¬nh giao thÃ´ng",
        "Ä‘Æ°á»ng nÃ o táº¯c",
        "táº¯c ngháº½n",
        "máº­t Ä‘á»™ giao thÃ´ng",
        "Ä‘Æ°á»ng Ä‘Ã´ng",
        "Ä‘ang táº¯c",
        "bá»‹ táº¯c",
        "Ä‘ang káº¹t",
        "bá»‹ káº¹t",
        "Ä‘ang Ä‘Ã´ng",
        "chá»— nÃ o táº¯c",
        "nÃ o Ä‘ang táº¯c",
        # Location-based queries
        "vá»‹ trÃ­ cá»§a tÃ´i",
        "chá»— tÃ´i",
        "nÆ¡i tÃ´i",
        "khu vá»±c cá»§a tÃ´i",
        "gáº§n tÃ´i",
        "quanh tÃ´i",
        "xung quanh tÃ´i",
        "vá»‹ trÃ­ hiá»‡n táº¡i",
    ]

    # Blacklist: Definitely off-topic keywords
    OFF_TOPIC_KEYWORDS = [
        # Technology (not traffic)
        "láº­p trÃ¬nh",
        "code",
        "coding",
        "python",
        "javascript",
        "java",
        "website",
        "app",
        "á»©ng dá»¥ng",
        "pháº§n má»m",
        "software",
        "mÃ¡y tÃ­nh",
        "computer",
        "laptop",
        "Ä‘iá»‡n thoáº¡i",
        "iphone",
        "android",
        "ai",
        "machine learning",
        "chatgpt",
        "gpt",
        # Entertainment
        "phim",
        "movie",
        "game",
        "trÃ² chÆ¡i",
        "nháº¡c",
        "music",
        "ca sÄ©",
        "diá»…n viÃªn",
        "youtube",
        "tiktok",
        "facebook",
        "instagram",
        # Food
        "náº¥u Äƒn",
        "mÃ³n Äƒn",
        "thá»©c Äƒn",
        "nhÃ  hÃ ng",
        "quÃ¡n Äƒn",
        "Ä‘á»“ Äƒn",
        "recipe",
        "cÃ´ng thá»©c náº¥u",
        "phá»Ÿ",
        "bÃºn",
        "cÆ¡m",
        "náº¥u",
        # Relationships
        "tÃ¬nh yÃªu",
        "ngÆ°á»i yÃªu",
        "báº¡n gÃ¡i",
        "báº¡n trai",
        "háº¹n hÃ²",
        "káº¿t hÃ´n",
        "ly hÃ´n",
        "gia Ä‘Ã¬nh",
        "tÃ¡n gÃ¡i",
        "tÃ¡n trai",
        "crush",
        # Sports (not traffic)
        "bÃ³ng Ä‘Ã¡",
        "bÃ³ng rá»•",
        "tennis",
        "cáº§u lÃ´ng",
        "thá»ƒ thao",
        "world cup",
        "euro",
        "olympic",
        # Finance (not traffic-related)
        "crypto",
        "bitcoin",
        "chá»©ng khoÃ¡n",
        "cá»• phiáº¿u",
        "Ä‘áº§u tÆ°",
        "forex",
        "ngÃ¢n hÃ ng",
        "vay tiá»n",
        # Health (general)
        "bá»‡nh",
        "thuá»‘c",
        "bÃ¡c sÄ©",
        "bá»‡nh viá»‡n",
        "sá»©c khá»e",
        "covid",
        "vaccine",
        "tiÃªm",
        # Weather
        "thá»i tiáº¿t",
        "mÆ°a",
        "náº¯ng",
        "bÃ£o",
        "nhiá»‡t Ä‘á»™",
        # Politics (sensitive)
        "chÃ­nh trá»‹",
        "báº§u cá»­",
        "Ä‘áº£ng",
        "chÃ­nh phá»§",
        # Other
        "há»c tiáº¿ng anh",
        "du lá»‹ch",
        "khÃ¡ch sáº¡n",
        "vÃ© mÃ¡y bay",
        "mua sáº¯m",
        "shopping",
        "quáº§n Ã¡o",
        "giÃ y dÃ©p",
        "lÃ m Ä‘áº¹p",
        "trang Ä‘iá»ƒm",
        "skincare",
    ]

    # Rejection response templates
    REJECTION_RESPONSES = {
        "default": """Xin lá»—i, tÃ´i lÃ  **TECHNO TRAFFIX** â€” trá»£ lÃ½ chuyÃªn vá» Luáº­t An toÃ n giao thÃ´ng Ä‘Æ°á»ng bá»™ Viá»‡t Nam.

TÃ´i chá»‰ cÃ³ thá»ƒ há»— trá»£ cÃ¡c cÃ¢u há»i vá»:
- ðŸš— Má»©c pháº¡t vi pháº¡m giao thÃ´ng (Nghá»‹ Ä‘á»‹nh 168/2024)
- ðŸ“‹ Quy Ä‘á»‹nh vá» Giáº¥y phÃ©p lÃ¡i xe (GPLX)
- ðŸš¦ Quy táº¯c giao thÃ´ng Ä‘Æ°á»ng bá»™
- ðŸº Quy Ä‘á»‹nh vá» ná»“ng Ä‘á»™ cá»“n
- âš¡ Tá»‘c Ä‘á»™ vÃ  biá»ƒn bÃ¡o giao thÃ´ng

Báº¡n cÃ³ cÃ¢u há»i gÃ¬ vá» giao thÃ´ng khÃ´ng? **TECHNO TRAFFIX** luÃ´n sáºµn sÃ ng há»— trá»£!""",
        "greeting": """Xin chÃ o! ðŸ‘‹

TÃ´i lÃ  **TECHNO TRAFFIX** â€” Trá»£ lÃ½ Luáº­t An toÃ n giao thÃ´ng Ä‘Æ°á»ng bá»™ Viá»‡t Nam.

**TECHNO TRAFFIX** cÃ³ thá»ƒ giÃºp báº¡n:
- ðŸ“– Tra cá»©u má»©c pháº¡t vi pháº¡m giao thÃ´ng (theo NÄ 168/2024)
- ðŸªª ThÃ´ng tin vá» GPLX vÃ  há»‡ thá»‘ng trá»« Ä‘iá»ƒm (tá»« 01/01/2025)
- ðŸš— Quy Ä‘á»‹nh tá»‘c Ä‘á»™, ná»“ng Ä‘á»™ cá»“n
- ðŸš¦ CÃ¡c quy táº¯c giao thÃ´ng Ä‘Æ°á»ng bá»™ khÃ¡c

HÃ£y há»i **TECHNO TRAFFIX** báº¥t cá»© Ä‘iá»u gÃ¬ vá» luáº­t giao thÃ´ng!""",
        "thanks": """KhÃ´ng cÃ³ chi! ðŸ˜Š

**TECHNO TRAFFIX** luÃ´n sáºµn sÃ ng há»— trá»£ báº¡n. Náº¿u cÃ³ thÃªm cÃ¢u há»i vá» luáº­t giao thÃ´ng, Ä‘á»«ng ngáº¡i há»i nhÃ©!""",
        "goodbye": """Táº¡m biá»‡t! ðŸ‘‹

**TECHNO TRAFFIX** chÃºc báº¡n lÃ¡i xe an toÃ n! Nhá»› tuÃ¢n thá»§ luáº­t giao thÃ´ng nhÃ©! ðŸš—âœ¨""",
    }

    def __init__(self):
        """Initialize the validator with compiled patterns."""
        # Pre-compile greeting patterns for performance
        self._greeting_patterns = [
            re.compile(pattern, re.IGNORECASE | re.UNICODE) for pattern in self.GREETING_PATTERNS
        ]

        # Normalize keywords for faster lookup
        self._traffic_keywords = set(kw.lower() for kw in self.TRAFFIC_KEYWORDS)
        self._off_topic_keywords = set(kw.lower() for kw in self.OFF_TOPIC_KEYWORDS)

    def _normalize_text(self, text: str) -> str:
        """Normalize Vietnamese text for matching."""
        text = text.lower().strip()
        # Remove extra whitespace
        text = re.sub(r"\s+", " ", text)
        return text

    def _check_greeting(self, text: str) -> Tuple[bool, Optional[str]]:
        """
        Check if message is a greeting or common interaction.
        Returns (is_greeting, response_key)
        """
        text_lower = text.lower().strip()

        for pattern in self._greeting_patterns:
            if pattern.search(text_lower):
                # Determine response type
                if any(word in text_lower for word in ["cáº£m Æ¡n", "thank", "cÃ¡m Æ¡n"]):
                    return True, "thanks"
                elif any(word in text_lower for word in ["táº¡m biá»‡t", "bye", "goodbye"]):
                    return True, "goodbye"
                else:
                    return True, "greeting"

        return False, None

    def _count_keyword_matches(self, text: str, keywords: set) -> Tuple[int, List[str]]:
        """Count how many keywords from a set appear in the text."""
        text_normalized = self._normalize_text(text)
        matches = []

        for keyword in keywords:
            if keyword in text_normalized:
                matches.append(keyword)

        return len(matches), matches

    def _calculate_traffic_score(self, text: str) -> Tuple[float, List[str]]:
        """
        Calculate relevance score for traffic-related content.
        Returns (score 0-1, matched_keywords)
        """
        traffic_count, traffic_matches = self._count_keyword_matches(text, self._traffic_keywords)
        off_topic_count, _ = self._count_keyword_matches(text, self._off_topic_keywords)

        # If off-topic keywords dominate, lower the score
        if off_topic_count > 0 and traffic_count == 0:
            return 0.0, []

        # Calculate score based on keyword density
        if traffic_count == 0:
            return 0.0, []

        # More traffic keywords = higher confidence
        # Penalize if off-topic keywords present
        base_score = min(traffic_count * 0.25, 1.0)
        penalty = off_topic_count * 0.15

        final_score = max(0.0, min(1.0, base_score - penalty))

        return final_score, traffic_matches

    def _detect_category(self, text: str, matched_keywords: List[str]) -> TopicCategory:
        """Detect the specific traffic category based on keywords."""
        text_lower = text.lower()

        # Traffic status / congestion queries (check early â€“ takes priority)
        if any(kw in text_lower for kw in [
            "Ã¹n táº¯c", "táº¯c Ä‘Æ°á»ng", "káº¹t xe", "Ä‘Ã´ng xe", "tÃ¬nh hÃ¬nh giao thÃ´ng",
            "Ä‘Æ°á»ng nÃ o táº¯c", "táº¯c ngháº½n", "máº­t Ä‘á»™ giao thÃ´ng", "Ä‘Æ°á»ng Ä‘Ã´ng",
            "Ä‘ang táº¯c", "bá»‹ táº¯c", "Ä‘ang káº¹t", "bá»‹ káº¹t", "Ä‘ang Ä‘Ã´ng",
            "chá»— nÃ o táº¯c", "nÃ o Ä‘ang táº¯c",
            "vá»‹ trÃ­ cá»§a tÃ´i", "chá»— tÃ´i", "nÆ¡i tÃ´i", "khu vá»±c cá»§a tÃ´i",
            "gáº§n tÃ´i", "quanh tÃ´i", "xung quanh tÃ´i", "vá»‹ trÃ­ hiá»‡n táº¡i",
        ]):
            return TopicCategory.TRAFFIC_STATUS

        # Check specific categories
        if any(kw in text_lower for kw in ["ná»“ng Ä‘á»™ cá»“n", "rÆ°á»£u bia", "uá»‘ng rÆ°á»£u", "say"]):
            return TopicCategory.ALCOHOL_REGULATION

        if any(kw in text_lower for kw in ["báº±ng lÃ¡i", "gplx", "giáº¥y phÃ©p lÃ¡i", "háº¡ng a", "háº¡ng b", "háº¡ng c"]):
            return TopicCategory.DRIVER_LICENSE

        if any(kw in text_lower for kw in ["tá»‘c Ä‘á»™", "km/h", "cháº¡y nhanh", "quÃ¡ tá»‘c"]):
            return TopicCategory.SPEED_LIMIT

        if any(kw in text_lower for kw in ["Ä‘Ã¨n Ä‘á»", "biá»ƒn bÃ¡o", "váº¡ch káº»"]):
            return TopicCategory.TRAFFIC_SIGNS

        if any(kw in text_lower for kw in ["tai náº¡n", "va cháº¡m", "Ä‘Ã¢m", "tÃ´ng"]):
            return TopicCategory.ACCIDENT

        if any(kw in text_lower for kw in ["pháº¡t", "vi pháº¡m", "xá»­ pháº¡t", "má»©c pháº¡t"]):
            return TopicCategory.TRAFFIC_VIOLATION

        if any(kw in text_lower for kw in ["Ä‘Äƒng kÃ½", "Ä‘Äƒng kiá»ƒm", "báº£o hiá»ƒm"]):
            return TopicCategory.VEHICLE_REGISTRATION

        # Default to general traffic rules
        return TopicCategory.TRAFFIC_RULES

    def validate(self, message: str) -> ValidationResult:
        """
        Validate if a message is related to Vietnamese traffic law.

        Args:
            message: User's input message

        Returns:
            ValidationResult with validation status and details
        """
        if not message or not message.strip():
            return ValidationResult(
                is_valid=False,
                confidence=1.0,
                category=TopicCategory.OFF_TOPIC,
                reason="Empty message",
                suggested_response="Báº¡n chÆ°a nháº­p ná»™i dung. HÃ£y há»i tÃ´i vá» luáº­t giao thÃ´ng nhÃ©!",
            )

        text = message.strip()

        # Step 1: Check for greetings
        is_greeting, greeting_type = self._check_greeting(text)
        if is_greeting:
            return ValidationResult(
                is_valid=True,
                confidence=1.0,
                category=TopicCategory.GREETING,
                reason="Greeting detected",
                suggested_response=self.REJECTION_RESPONSES[greeting_type]
                if greeting_type
                else self.REJECTION_RESPONSES["greeting"],
            )

        # Step 2: Check for off-topic keywords first (blacklist)
        off_topic_count, off_topic_matches = self._count_keyword_matches(text, self._off_topic_keywords)
        traffic_score, traffic_matches = self._calculate_traffic_score(text)

        # If clearly off-topic (blacklist matches and no traffic keywords)
        if off_topic_count > 0 and traffic_score < 0.3:
            return ValidationResult(
                is_valid=False,
                confidence=min(off_topic_count * 0.3, 1.0),
                category=TopicCategory.OFF_TOPIC,
                reason=f"Off-topic keywords detected: {off_topic_matches[:3]}",
                suggested_response=self.REJECTION_RESPONSES["default"],
            )

        # Step 3: Check for traffic keywords (whitelist)
        if traffic_score >= 0.3:
            category = self._detect_category(text, traffic_matches)
            return ValidationResult(
                is_valid=True,
                confidence=traffic_score,
                category=category,
                reason=f"Traffic-related keywords found: {traffic_matches[:5]}",
            )

        # Step 4: Edge case - no clear indicators
        # For short messages without keywords, assume it might be a follow-up question
        # Let it through with low confidence (LLM will handle context)
        if len(text.split()) <= 5:
            return ValidationResult(
                is_valid=True,
                confidence=0.3,
                category=TopicCategory.TRAFFIC_RULES,
                reason="Short message, might be follow-up question",
            )

        # Default: Reject unclear long messages
        return ValidationResult(
            is_valid=False,
            confidence=0.5,
            category=TopicCategory.OFF_TOPIC,
            reason="No traffic-related content detected",
            suggested_response=self.REJECTION_RESPONSES["default"],
        )

    def get_intent(self, validation_result: ValidationResult) -> Optional[str]:
        """
        Convert validation category to intent string for RAG search.
        """
        category_to_intent = {
            TopicCategory.TRAFFIC_VIOLATION: "traffic_violation",
            TopicCategory.DRIVER_LICENSE: "license_query",
            TopicCategory.SPEED_LIMIT: "speed_limit",
            TopicCategory.ALCOHOL_REGULATION: "alcohol_regulation",
            TopicCategory.TRAFFIC_STATUS: "traffic_status",
            TopicCategory.TRAFFIC_RULES: None,  # General search
            TopicCategory.TRAFFIC_SIGNS: None,
            TopicCategory.VEHICLE_REGISTRATION: None,
            TopicCategory.INSURANCE: None,
            TopicCategory.ACCIDENT: None,
        }
        return category_to_intent.get(validation_result.category)
